# Aura Platform Architecture

## Overview
Aura is an Agent-Oriented Service Gateway designed to facilitate autonomous economic negotiations between AI agents and service providers.

## Core Components

### System Landscape (C4 Container Diagram)

```mermaid
graph TD
    subgraph Clients ["Clients (The Edge)"]
        Browser["Agent Console (Next.js)"]
        Bot["Autonomous Agent<br>(Python Script)"]
    end

    subgraph Infrastructure ["Aura Platform (Network)"]
        
        %% Entry Point
        Gateway["API Gateway (FastAPI)"]
        style Gateway fill:#f9f,stroke:#333,stroke-width:2px
        
        %% The Brain
        Core["Core Engine (gRPC/Python)"]
        style Core fill:#bbf,stroke:#333,stroke-width:2px
        
        %% Storage Layer
        DB[("PostgreSQL<br>(pgvector)")]
        Redis[("Redis<br>(Cache & State)")]
        
        %% Observability
        Jaeger["Jaeger Tracing"]
    end
    
    subgraph External ["External World"]
        Mistral["Mistral AI API"]
    end

    %% Connections
    Browser -- "HTTP/JSON + Signed Headers" --> Gateway
    Bot -- "HTTP/JSON + Signed Headers" --> Gateway
    
    Gateway -- "gRPC (Protobuf)" --> Core
    Gateway -. "Rate Limiting Check" -.-> Redis
    Gateway -. "Trace Spans" -.-> Jaeger

    Core -- "SQL / Vector Search" --> DB
    Core -- "Get/Set Session & Semantic Cache" --> Redis
    Core -- "LLM Inference" --> Mistral
    Core -. "Trace Spans" -.-> Jaeger

    %% Key
    linkStyle 0,1 stroke-width:2px,fill:none,stroke:green;
    linkStyle 2 stroke-width:4px,fill:none,stroke:blue;
    linkStyle 5,6 fill:none,stroke:purple;
```

**Legend:**
- ðŸŸ¢ **Green links**: Client traffic (HTTP/JSON requests from external agents)
- ðŸ”µ **Blue links**: Internal gRPC calls (Protobuf communication between services)
- ðŸŸ£ **Purple links**: Database operations (SQL queries to PostgreSQL)

### 1. API Gateway (The Diplomat)
- **Tech**: Python / FastAPI / Uvicorn
- **Port**: 8000
- **Role**: 
  - Validates Agent Identity (DID/Tokens).
  - Translates HTTP JSON requests to internal gRPC calls.
  - Handles Rate Limiting.

### 2. Core Engine (The Brain)
- **Tech**: Python / gRPC / LangChain / SQLAlchemy
- **Port**: 50051
- **Role**:
  - Manages `Inventory` and `NegotiationSession`.
  - Executes `PricingStrategy` (Rule-based or LLM-based).
  - Enforces `floor_price` logic.

### 3. Storage Layer
- **PostgreSQL**: Stores inventory items and structured negotiation logs.
- **pgvector** (Planned): Will store semantic embeddings for search.

## Data Flow (Negotiation)

```mermaid
sequenceDiagram
    participant Agent
    participant Gateway
    participant Core
    participant Redis
    participant DB as Postgres (Vector)
    participant AI as Mistral LLM

    Agent->>Gateway: POST /negotiate (Bid: $900, Signed)
    
    Note over Gateway: 1. Verify Signature (Ed25519)<br/>2. Check Rate Limit (Redis)
    
    Gateway->>Core: gRPC Negotiate(item_id, bid)
    
    Note over Core: Start Span (Tracing)
    
    %% Semantic Caching Layer
    Core->>Redis: GET "semantic_hash(item+bid)"
    alt Cache Hit (Fast Path)
        Redis-->>Core: JSON {decision: "counter", price: 950}
        Core-->>Gateway: Response (from Cache)
        Gateway-->>Agent: 200 OK (5ms latency)
    else Cache Miss (Slow Path)
        Core->>DB: SELECT floor_price, embedding FROM items
        DB-->>Core: floor: $800, vec: [...]
        
        Core->>AI: "Analyze Bid $900 vs Floor $800"
        AI-->>Core: {decision: "accept", reasoning: "..."}
        
        par Async Write
            Core->>Redis: SETEX "semantic_hash", TTL=1h
            Core->>DB: INSERT INTO negotiation_logs
        end
        
        Core-->>Gateway: Response (Fresh)
        Gateway-->>Agent: 200 OK (1.5s latency)
    end
```

## Key Decisions
- **Contract-First**: All APIs defined in `proto/aura/negotiation/v1/`.
- **Stateless Strategies**: Logic does not keep state in memory; all context comes from DB.
- **Hidden Knowledge**: Agents never see `floor_price` directly.